{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# The Evolution of the American Presidency #\n",
      "\n",
      "#### Renzo Lucioni, Kathy Lin, Sherrie Wang, Matt Moellman ####"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# special IPython command to prepare the notebook for matplotlib\n",
      "%matplotlib inline \n",
      "\n",
      "from fnmatch import fnmatch\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import requests\n",
      "from pattern import web\n",
      "import json\n",
      "\n",
      "\n",
      "# set some nicer defaults for matplotlib\n",
      "from matplotlib import rcParams\n",
      "\n",
      "#these colors come from colorbrewer2.org. Each is an RGB triplet\n",
      "dark2_colors = [(0.10588235294117647, 0.6196078431372549, 0.4666666666666667),\n",
      "                (0.8509803921568627, 0.37254901960784315, 0.00784313725490196),\n",
      "                (0.4588235294117647, 0.4392156862745098, 0.7019607843137254),\n",
      "                (0.9058823529411765, 0.1607843137254902, 0.5411764705882353),\n",
      "                (0.4, 0.6509803921568628, 0.11764705882352941),\n",
      "                (0.9019607843137255, 0.6705882352941176, 0.00784313725490196),\n",
      "                (0.6509803921568628, 0.4627450980392157, 0.11372549019607843),\n",
      "                (0.4, 0.4, 0.4)]\n",
      "\n",
      "rcParams['figure.figsize'] = (10, 6)\n",
      "rcParams['figure.dpi'] = 150\n",
      "rcParams['axes.color_cycle'] = dark2_colors\n",
      "rcParams['lines.linewidth'] = 2\n",
      "rcParams['axes.grid'] = True\n",
      "rcParams['axes.facecolor'] = '#eeeeee'\n",
      "rcParams['font.size'] = 14\n",
      "rcParams['patch.edgecolor'] = 'none'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Insert introduction*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Data Collection ###\n",
      "\n",
      "We will gather our data by scraping the [data](http://www.presidency.ucsb.edu/data.php) and [documents](http://www.presidency.ucsb.edu/index_docs.php) web archives maintained by The American Presidency Project at UCSB. We'll start by scraping the State of the Union addresses in the documents archive."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_sotu(url):\n",
      "    \"Given a url of a sotu speech, get president, year, and text. Return dictionary.\"\n",
      "    html = requests.get(url).text\n",
      "    dom = web.Element(html)\n",
      "    data = {}\n",
      "    i = dom.by_tag('meta')[3]\n",
      "    data['president'] = i.attributes['content'].split(':')[0]\n",
      "    data['year'] = i.attributes['content'].split('-')[-1].split()[-1]\n",
      "    text = dom.by_tag('span.displaytext')[0].content\n",
      "    for p in dom.by_tag('p'):\n",
      "        t = p.content\n",
      "        if fnmatch(t, \"*<hr*\"):\n",
      "            text += t.split('<hr')[0]\n",
      "        elif fnmatch(t, \"*<div*\"):\n",
      "            text += t.split('<div')[0]\n",
      "        else:\n",
      "            text += p.content\n",
      "    data['text'] = text\n",
      "    return data\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_all_sotu():\n",
      "    \"Visits website with links to all sotus. Uses get_sotu to pull each one. Writes to file.\"\n",
      "    url = \"http://www.presidency.ucsb.edu/sou.php\"\n",
      "    html = requests.get(url).text\n",
      "    dom = web.Element(html)\n",
      "    sotus = []\n",
      "    for link in web.find_urls(dom):\n",
      "        if fnmatch(link, \"*pid*\"):\n",
      "            sotus.append(get_sotu(link))\n",
      "    \n",
      "    f = open('sotus.json', 'w')\n",
      "    f.write(json.dumps(sotus, indent=2))\n",
      "    f.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# toggle to scrape and store SOTU data\n",
      "# get_all_sotu()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('sotus.json')\n",
      "raw = f.read()\n",
      "data = json.loads(raw)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}